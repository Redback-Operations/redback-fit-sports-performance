{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cd79b04-f790-4ef5-a5f7-7006b1e89a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billt\\AppData\\Local\\Temp\\ipykernel_36456\\3526498789.py:26: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_daily[\"dist\"].fillna(0, inplace=True)\n",
      "C:\\Users\\billt\\AppData\\Local\\Temp\\ipykernel_36456\\3526498789.py:27: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_daily[\"Calories\"].fillna(0, inplace=True)\n",
      "C:\\Users\\billt\\AppData\\Local\\Temp\\ipykernel_36456\\3526498789.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub[feature_cols] = scaler.transform(sub[feature_cols])\n",
      "C:\\Users\\billt\\AppData\\Local\\Temp\\ipykernel_36456\\3526498789.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub[feature_cols] = scaler.transform(sub[feature_cols])\n",
      "C:\\Users\\billt\\AppData\\Local\\Temp\\ipykernel_36456\\3526498789.py:62: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sub[feature_cols] = scaler.transform(sub[feature_cols])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 - 7s - 2s/step - auc: 0.4545 - loss: 0.6984 - val_auc: 0.0000e+00 - val_loss: 0.7602\n",
      "Epoch 2/200\n",
      "3/3 - 0s - 64ms/step - auc: 0.7731 - loss: 0.6699 - val_auc: 0.0000e+00 - val_loss: 0.8001\n",
      "Epoch 3/200\n",
      "3/3 - 0s - 63ms/step - auc: 0.8310 - loss: 0.6541 - val_auc: 0.0000e+00 - val_loss: 0.8395\n",
      "Epoch 4/200\n",
      "3/3 - 0s - 67ms/step - auc: 0.8380 - loss: 0.6332 - val_auc: 0.0000e+00 - val_loss: 0.8784\n",
      "Epoch 5/200\n",
      "3/3 - 0s - 68ms/step - auc: 0.8573 - loss: 0.6155 - val_auc: 0.0000e+00 - val_loss: 0.9190\n",
      "Epoch 6/200\n",
      "3/3 - 0s - 63ms/step - auc: 0.8711 - loss: 0.6028 - val_auc: 0.0000e+00 - val_loss: 0.9674\n",
      "Epoch 7/200\n",
      "3/3 - 0s - 78ms/step - auc: 0.8619 - loss: 0.5859 - val_auc: 0.0000e+00 - val_loss: 1.0040\n",
      "Epoch 8/200\n",
      "3/3 - 0s - 136ms/step - auc: 0.8789 - loss: 0.5582 - val_auc: 0.0000e+00 - val_loss: 1.0218\n",
      "Epoch 9/200\n",
      "3/3 - 0s - 77ms/step - auc: 0.8719 - loss: 0.5473 - val_auc: 0.0000e+00 - val_loss: 1.0297\n",
      "Epoch 10/200\n",
      "3/3 - 1s - 203ms/step - auc: 0.8557 - loss: 0.5545 - val_auc: 0.0000e+00 - val_loss: 1.0432\n",
      "Epoch 11/200\n",
      "3/3 - 0s - 121ms/step - auc: 0.8619 - loss: 0.5374 - val_auc: 0.0000e+00 - val_loss: 1.0656\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 349ms/step\n",
      "Test AUC = 0.500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.50      1.00      0.67         1\n",
      "         1.0       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.50         2\n",
      "   macro avg       0.25      0.50      0.33         2\n",
      "weighted avg       0.25      0.50      0.33         2\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\billt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\billt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "C:\\Users\\billt\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\metrics\\_classification.py:1731: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "# ------------------------------------------------------------\n",
    "# 0. Imports\n",
    "# ------------------------------------------------------------\n",
    "import pandas as pd, numpy as np, tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1. Load & resample to daily granularity\n",
    "# ------------------------------------------------------------\n",
    "df = pd.read_csv(\"Fixed_cleaned_activities.csv\",\n",
    "                 parse_dates=[\"Begin Timestamp\"], dayfirst=True)\n",
    "\n",
    "df = df.sort_values(\"Begin Timestamp\")\n",
    "df_daily = (\n",
    "    df.set_index(\"Begin Timestamp\")\n",
    "      .resample(\"D\")\n",
    "      .agg({\"Distance (Raw)\": \"sum\",        # or first/mean as sensible\n",
    "            \"Calories\": \"sum\",\n",
    "            \"Average Heart Rate (bpm)\": \"mean\"})\n",
    "      .rename(columns={\"Distance (Raw)\": \"dist\"})\n",
    ")\n",
    "\n",
    "# fill missing days (no session) with zeros / NaNs as appropriate\n",
    "df_daily[\"dist\"].fillna(0, inplace=True)\n",
    "df_daily[\"Calories\"].fillna(0, inplace=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2. Rolling-load features\n",
    "# ------------------------------------------------------------\n",
    "df_daily[\"acute_load\"]   = df_daily[\"dist\"].rolling(\"7D\").sum()\n",
    "df_daily[\"chronic_load\"] = df_daily[\"dist\"].rolling(\"28D\").sum()/4\n",
    "df_daily[\"acwr\"]         = df_daily[\"acute_load\"] / df_daily[\"chronic_load\"]\n",
    "df_daily[\"acwr\"]         = df_daily[\"acwr\"].replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# binary label: risk today (threshold 1.5)\n",
    "df_daily[\"injury_risk\"]  = (df_daily[\"acwr\"] > 1.5).astype(int)\n",
    "\n",
    "# drop first 28 days (no full window yet) and rows with NaNs\n",
    "df_daily = df_daily.dropna()\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3. Normalise numeric columns (fit on train split only)\n",
    "# ------------------------------------------------------------\n",
    "feature_cols = [\"dist\", \"Calories\", \"Average Heart Rate (bpm)\",\n",
    "                \"acute_load\", \"chronic_load\", \"acwr\"]\n",
    "\n",
    "# chronological split idx\n",
    "test_frac = 0.2\n",
    "val_frac  = 0.2\n",
    "n_total   = len(df_daily)\n",
    "n_test    = int(n_total * test_frac)\n",
    "n_val     = int(n_total * val_frac)\n",
    "\n",
    "train_df = df_daily.iloc[:-(n_val + n_test)]\n",
    "val_df   = df_daily.iloc[-(n_val + n_test):-n_test]\n",
    "test_df  = df_daily.iloc[-n_test:]\n",
    "\n",
    "scaler = StandardScaler().fit(train_df[feature_cols])\n",
    "for sub in (train_df, val_df, test_df):\n",
    "    sub[feature_cols] = scaler.transform(sub[feature_cols])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4. Turn into 3-D arrays (samples, time, features)\n",
    "# ------------------------------------------------------------\n",
    "def make_windows(dataframe, window_size=28, label_offset=0):\n",
    "    X, y = [], []\n",
    "    values = dataframe[feature_cols + [\"injury_risk\"]].values\n",
    "    for i in range(window_size, len(values) - label_offset):\n",
    "        X.append(values[i-window_size:i, :-1])\n",
    "        y.append(values[i + label_offset, -1])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "window_size, label_offset = 28, 0\n",
    "X_train, y_train = make_windows(train_df, window_size, label_offset)\n",
    "X_val, y_val     = make_windows(val_df,   window_size, label_offset)\n",
    "X_test, y_test   = make_windows(test_df,  window_size, label_offset)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5. Compute class weights (handle imbalance)\n",
    "# ------------------------------------------------------------\n",
    "cw = class_weight.compute_class_weight(\n",
    "        \"balanced\",\n",
    "        classes=np.unique(y_train),\n",
    "        y=y_train\n",
    "     )\n",
    "class_wt = {0: cw[0], 1: cw[1]}\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 6. LSTM model\n",
    "# ------------------------------------------------------------\n",
    "tf.random.set_seed(42)\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(window_size, len(feature_cols))),\n",
    "    layers.Masking(mask_value=0.0),           # optional, if you zero-pad\n",
    "    layers.LSTM(64, return_sequences=False),\n",
    "    layers.Dropout(0.3),\n",
    "    layers.Dense(32, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[tf.keras.metrics.AUC(name=\"auc\")])\n",
    "\n",
    "cb = callbacks.EarlyStopping(monitor=\"val_auc\",\n",
    "                             patience=10, mode=\"max\",\n",
    "                             restore_best_weights=True)\n",
    "\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=200,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(X_val, y_val),\n",
    "                    class_weight=class_wt,\n",
    "                    callbacks=[cb],\n",
    "                    verbose=2)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 7. Evaluation\n",
    "# ------------------------------------------------------------\n",
    "test_preds = model.predict(X_test).flatten()\n",
    "test_auc   = tf.keras.metrics.AUC()(y_test, test_preds).numpy()\n",
    "print(f\"Test AUC = {test_auc:.3f}\")\n",
    "\n",
    "# Confusion threshold at 0.5 (tune if needed)\n",
    "test_labels = (test_preds >= 0.5).astype(int)\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a997c66-1c2b-4a36-a19a-03984ae36a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
